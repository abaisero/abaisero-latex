\documentclass{article}

\usepackage[margin=1in]{geometry}
\usepackage{booktabs}
\usepackage{hyperref}

\usepackage{abaisero}

\begin{document}

\title{abaisero.sty}
\author{Andrea Baisero}

\newcommand\option[1]{\texttt{#1}}
\newcommand\command[1]{\texttt{\textbackslash{#1}}}

\newcommand\xset{\mathcal{X}}
\newcommand\yset{\mathcal{Y}}

\maketitle

\section{Options}

Options are processes left-to-right.
If no options are provided, or none are enabled by the end of the processing, then by default they are all considered to be enabled.

\begin{table}[h]
\begin{tabular}{ll}
  %
  \toprule
  %
  Option & Description \\
  %
  \midrule
  %
  \option{all} & Enable all commands \\
  %
  \option{(no-)math} & Disable/enable mathematical commands \\
  %
  \option{(no-)linalg} & Disable/enable linear algebra commands \\
  %
  \option{(no-)optim} & Disable/enable optimization commands \\
  %
  \option{(no-)stats} & Disable/enable statistics commands \\
  %
  \option{(no-)dists} & Disable/enable distributions commands \\
  %
  \option{(no-)ml} & Disable/enable machine learning commands \\
  %
  \option{(no-)rl} & Disable/enable reinforcement learning commands \\
  %
  \option{(no-)marl} & Disable/enable multi-agent reinforcement learning commands \\
  %
  \option{(no-)theorem} & Disable/enable theorem commands \\
  %
  \option{(no-)misc} & Disable/enable miscellanea commands \\
  %
  \bottomrule
  %
\end{tabular}
\end{table}

\section{Commands}

\subsection*{Option [math]}

\begin{tabular}{clll}
  %
  \toprule
  %
  Symbol & Command & Description & Example \\
  %
  \midrule
  %
  $\naturalset$ & \command{naturalset} & the set of natural numbers & $\naturalset \doteq \{ 1, 2, 3, \ldots \}$ \\
  %
  $\integerset$ & \command{integerset} & the set of integer numbers & $\integerset \doteq \{ 0, 1, -1, 2, -3, \ldots \}$ \\
  %
  $\realset$ & \command{realset} & the set of real numbers & $\sqrt{2} \in \realset$ \\
  %
  $\kstar$ & \command{kstar} & the Kleene star operator & $\xset\kstar \doteq \bigcup_{k=0}^\infty \xset^k$ \\
  %
  $\kplus$ & \command{kplus} & the Kleene plus operator & $\xset\kplus \doteq \bigcup_{k=1}^\infty \xset^k$ \\
  %
  $\softmax$ & \command{softmax} & a.k.a. logsumexp, realsoftmax\footnotemark[1] & $\softmax(x_1, \ldots, x_n) \doteq \log\sum_i \exp(x_i)$ \\
  %
  $\softmin$ & \command{softmin} & & $\softmin(x_1, \ldots, x_n) \doteq -\log\sum_i \exp(-x_i)$ \\
  %
  $\softargmax$ & \command{softargmax} & a.k.a. softmax\footnotemark[1] & $\softargmax(x_1, \ldots, x_n)_i \doteq \frac{ \exp(x_i) }{ \sum_k \exp(x_k) } $ \\
  %
  $\sign$ & \command{sign} & & $x = \sign{x} \cdot |x|$ \\
  %
  $\supp$ & \command{supp} & support operator & $\supp(f) \doteq \{ x \mid f(x) \neq 0 \}$ \\
  %
  \bottomrule
  %
\end{tabular}

\footnotetext[1]{The functions that in this document are called ``softmax'' and ``softargmax'' are poorly and inaccurately named in the broader math and ML fields (see \url{https://en.wikipedia.org/wiki/Softmax_function} and \url{https://en.wikipedia.org/wiki/LogSumExp}). Rather than stick to the more common naming conventions, I opt to rename the functions more accurately to appropriately reflect their actual properties. In any document where I would use these functions, I would need to define them anyway, so the risk of misunderstandings are minimal.}

\subsection*{Option [linalg]}

\begin{tabular}{clll}
  %
  \toprule
  %
  Symbol & Command & Description & Example \\
  %
  \midrule
  %
  $\diag$ & \command{diag} & & \\
  %
  $\rank$ & \command{rank} & & \\
  %
  $\trace$ & \command{trace} & & $\trace(M) \doteq \sum_{i=1}^n M_{ii}$ \\
  %
  $\colspace$ & \command{colspace} & & \\
  %
  $\nullspace$ & \command{nullspace} & Nullspace (a.k.a\ kernel) of a linear mapping & \\
  %
  $\spanspace$ & \command{spanspace} & & \\
  %
  $\T$ & \command{T} & Transpose superscript & symmetric $M \implies M = M\T$ \\
  %
  $\I$ & \command{I} & Inverse superscript & invertible $M \implies MM\I = I$ \\
  %
  $\PI$ & \command{PI} & Pseudo-inverse superscript & $MM\PI M = M$ \\
  %
  $\IT$ & \command{IT} & Inverse transpose superscript & $M\IT = (M\I)\T = (M\T)\I$ \\
  %
  $\PIT$ & \command{PIT} & Pseudo-inverse transpose superscript & $M\PIT = (M\PI)\T = (M\T)\PI$ \\
  %
  \bottomrule
  %
\end{tabular}

\subsection*{Option [optim]}

\begin{tabular}{clll}
  %
  \toprule
  %
  Symbol & Command & Description & Example \\
  %
  \midrule
  %
  $\argmax$ & \command{argmax} & & $\argmax_a \qpolicy(s, a)$ \\
  %
  $\argmin$ & \command{argmin} & & $\theta\opt \doteq \argmin_\theta \loss(\theta)$ \\
  %
  $\opt$ & \command{opt} & Optimality superscript & $\policy\opt(s) = \argmax_a Q\opt(s, a)$ \\
  %
  \bottomrule
  %
\end{tabular}

\subsection*{Option [stats]}

\begin{tabular}{clll}
  %
  \toprule
  %
  Symbol & Command & Description & Example \\
  %
  \midrule
  %
  $\indep$ & \command{indep} & Independence & $X \indep Y \mid Z$ \\
  %
  \midrule
  %
  $\causaldo$ & \command{causaldo} & Pearl's \emph{do} operator & $\Pr(Y\mid \causaldo(X=x)) \neq \Pr(Y\mid X=s)$ \\
  %
  \midrule
  %
  $\Cov$ & \command{Cov} & Covariance & $\Cov(x, y) = \Exp\left[xy\right] - \Exp\left[x\right] \Exp\left[y\right]$ \\
  %
  $\Ent$ & \command{Ent} & Entropy & $\Ent[x] = -\Exp\left[\log\Pr(x) \right]$ \\
  %
  $\Exp$ & \command{Exp} & Expectation & $\Exp\left[ f(x) \right] = \sum_x \Pr(x) f(x)$ \\
  %
  $\Ind$ & \command{Ind} & Indicator function & $\Pr(x=0) = \Exp\left[ \Ind\left[ x=0 \right] \right]$ \\
  %
  $\KL$ & \command{KL} & KL-divergence & $\KL\left( p \mid\mid q\right) \doteq \Exp_{x\sim p}\left[ \log p(x) - \log q(x) \right]$ \\
  %
  $\DKL$ & \command{DKL} & KL-divergence (alternative) & \\
  %
  $\MI$ & \command{MI} & Mutual Information & \\
  %
  $\Bias$ & \command{Bias} & Bias & $\Bias\left[\hat f(x)\right]$ is the bias of estimator $\hat f$ \\
  %
  $\Var$ & \command{Var} & Variance & $\Var\left[\hat f(x)\right] = \Exp\left[\hat f(x)^2\right] - \Exp\left[ \hat f(x)\right]^2$ \\
  %
  \bottomrule
  %
\end{tabular}

\subsection*{Option [dists]}

\begin{tabular}{cll}
  %
  \toprule
  %
  Symbol & Command & Description \\
  %
  \midrule
  %
  $\Categorical$ & \command{Categorical} & $\Categorical$ \\
  %
  $\Dirichlet$ & \command{Dirichlet} & $\Dirichlet$ \\
  %
  $\Geometric$ & \command{Geometric} & $\Geometric$ \\
  %
  $\Normal$ & \command{Normal} & $\Normal$ \\
  %
  $\Uniform$ & \command{Uniform} & $\Uniform$ \\
  %
  \bottomrule
  %
\end{tabular}

\subsection*{Option [ml]}

\begin{tabular}{clll}
  %
  \toprule
  %
  Symbol & Command & Description & Example \\
  %
  \midrule
  %
  $\data$ & \command{data} & Data set & $\data \doteq \{ (x_i, y_i) \}_{i=1}^N$ \\
  %
  $\loss$ & \command{loss} & Loss function & $\loss(\theta; x, y) = \frac{1}{2} \| y - f(x; \theta) \|^2$ \\
  %
  $\nll$ & \command{nll} & Neg-log-likelihood & $\nll(x) \doteq -\log\Pr(x)$ \\
  %
  $\mse$ & \command{mse} & Mean-squared-error & \\
  %
  \bottomrule
  %
\end{tabular}

\subsection*{Option [rl]}

\begin{tabular}{cll}
  %
  \toprule
  %
  Symbol & Command & Description \\
  %
  \midrule
  %
  $\aset$ & \command{aset } & Action set \\
  %
  $\bset$ & \command{bset } & Belief set \\
  %
  $\hset$ & \command{hset } & History set \\
  %
  $\oset$ & \command{oset } & Observation set \\
  %
  $\rset$ & \command{rset } & Reward set \\
  %
  $\sset$ & \command{sset } & State set \\
  %
  \midrule
  %
  $\dfn$ & \command{dfn } & Dynamics function \\
  %
  $\gfn$ & \command{gfn } & Generative function \\
  %
  $\ofn$ & \command{ofn} & Observation function \\
  %
  $\rfn$ & \command{rfn} & Reward function \\
  %
  $\tfn$ & \command{tfn} & Transition function \\
  %
  \midrule
  %
  $\nohistory$ & \command{nohistory} & Empty history \\
  %
  \midrule
  %
  $\policy$ & \command{policy} & policy \\
  %
  \midrule
  %
  $\qpolicy$ & \command{qpolicy} & Q policy values \\
  %
  $\qmodel$ & \command{qmodel} & Parametric model \\
  %
  \midrule
  %
  $\vpolicy$ & \command{vpolicy} & V policy values \\
  %
  $\vmodel$ & \command{vmodel} & Parametric model \\
  %
  \midrule
  %
  $\apolicy$ & \command{apolicy} & A policy values \\
  %
  $\amodel$ & \command{amodel} & Parametric model \\
  %
  \midrule
  %
  $\upolicy$ & \command{upolicy} & U policy values \\
  %
  $\umodel$ & \command{umodel} & Parametric model \\
  %
  \bottomrule
  %
\end{tabular}

\subsection*{Option [marl]}

\begin{tabular}{cll}
  %
  \toprule
  %
  Symbol & Command & Description \\
  %
  \midrule
  %
  $\hsset$ & \command{hsset} & Joint history set \\
  %
  $\asset$ & \command{asset} & Joint action set \\
  %
  $\osset$ & \command{osset} & Joint observation set \\
  %
  \midrule
  %
  $\hs$ & \command{hs} & Joint history \\
  %
  $\as$ & \command{as} & Joint action \\
  %
  $\os$ & \command{os} & Joint observation \\
  %
  \midrule
  %
  $\policies$ & \command{policies} & Joint policy \\
  %
  \midrule
  %
  $\qpolicies$ & \command{qpolicies} & Q joint-policy values \\
  %
  $\vpolicies$ & \command{vpolicies} & V joint-policy values \\
  %
  $\apolicies$ & \command{apolicies} & A joint-policy values \\
  %
  $\upolicies$ & \command{upolicies} & U joint-policy values \\
  %
  \bottomrule
  %
\end{tabular}

\subsection*{Option [theorem]}

\begin{tabular}{cll}
  %
  \toprule
  %
  Symbol & Command & Description \\
  %
  \midrule
  %
  & \command{begin\{definition\}} & \\
  %
  & \command{begin\{example\}} & \\
  %
  \midrule
  %
  & \command{begin\{axiom\}} & \\
  %
  & \command{begin\{conjecture\}} & \\
  %
  & \command{begin\{proposition\}} & \\
  %
  & \command{begin\{lemma\}} & \\
  %
  & \command{begin\{theorem\}} & \\
  %
  & \command{begin\{corollary\}} & \\
  %
  & \command{begin\{generalization\}} & \\
  %
  \bottomrule
  %
\end{tabular}

\subsection*{Option [misc]}

\begin{tabular}{cll}
  %
  \toprule
  %
  Symbol & Command & Description \\
  %
  \midrule
  %
  $\D$ & \command{D} & Dagger superscript \\
  %
  $\iter{k}$ & \command{iter\{k\}} & Superscript indicating iteration \\
  %
  \bottomrule
  %
\end{tabular}

\end{document}
